{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "pQvQfBTOoh8Y"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Gz6XeJ8co1mr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Timestamp  CAPITL  CENTRL  DUNWOD  GENESE    H Q  HUD VL  \\\n",
      "0       01/01/2000 00:00   42.88   39.49   43.70   38.98  39.98   42.92   \n",
      "1       01/01/2000 01:00   41.55   38.26   42.34   37.77  38.74   41.58   \n",
      "2       01/01/2000 02:00   40.98   37.74   41.76   37.25  38.20   41.01   \n",
      "3       01/01/2000 03:00   36.59   33.69   37.28   33.26  34.11   36.62   \n",
      "4       01/01/2000 04:00   42.88   39.49   43.70   38.98  39.98   42.92   \n",
      "...                  ...     ...     ...     ...     ...    ...     ...   \n",
      "222857  06/04/2025 19:00   59.72   57.66   60.76   56.99  55.75   60.25   \n",
      "222858  06/04/2025 20:00   58.57   57.73   59.75   57.56  55.74   59.41   \n",
      "222859  06/04/2025 21:00   50.16   48.17   49.49   47.88  47.53   49.30   \n",
      "222860  06/04/2025 22:00   41.36   40.40   42.16   40.00  39.93   41.84   \n",
      "222861  06/04/2025 23:00   36.23   35.46   37.07   35.39  34.70   36.89   \n",
      "\n",
      "        LONGIL  MHK VL  MILLWD  N.Y.C.  NORTH    NPX    O H    PJM   WEST  \n",
      "0        43.72   41.15   43.08   44.52  40.03  42.04  37.68  38.52  37.49  \n",
      "1        42.35   39.86   41.74   43.40  38.79  40.73  36.51  37.32  36.32  \n",
      "2        40.88   39.32   41.17   43.18  38.25  40.17  36.01  36.81  35.82  \n",
      "3        37.90   35.10   36.75   40.83  34.15  35.86  32.15  32.86  31.98  \n",
      "4        41.00   41.15   43.08   44.52  40.03  42.04  37.68  38.52  37.49  \n",
      "...        ...     ...     ...     ...    ...    ...    ...    ...    ...  \n",
      "222857   64.39   59.13   60.54   60.87  56.26  62.00  54.57  57.83  55.92  \n",
      "222858   63.00   59.08   59.64   59.81  56.54  59.34  55.06  57.20  56.54  \n",
      "222859   53.05   49.30   49.35   49.30  47.51  52.90  46.43  48.04  47.03  \n",
      "222860   46.72   41.44   42.00   42.40  40.13  42.12  38.64  40.40  39.32  \n",
      "222861   42.00   36.20   37.00   37.49  34.77  37.00  34.49  35.71  35.01  \n",
      "\n",
      "[222862 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "# prompt: read all the csv files \"D:\\OneDrive - The Pennsylvania State University\\Research DATA\\Dr. Habib & Dr. Reza Data\\Energy Price Market Data\\Day Ahead Price Data_Processed\\USA\\NYISO\" and merge into a one dataframe df\n",
    "\n",
    "folder_path = r\"D:\\OneDrive - The Pennsylvania State University\\Research DATA\\Dr. Habib & Dr. Reza Data\\Energy Price Market Data\\Day Ahead Price Data_Processed\\USA\\NYISO\"\n",
    "\n",
    "all_nyiso_data = pd.DataFrame()\n",
    "\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                df_temp = pd.read_csv(file_path)\n",
    "                all_nyiso_data = pd.concat([all_nyiso_data, df_temp], ignore_index=True)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {file_path}: {e}\")\n",
    "\n",
    "df = all_nyiso_data.copy() # Assign the concatenated dataframe to df\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "IzX21Pz0oovZ",
    "outputId": "78aa6604-6705-4a99-9346-50d94002d0c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>CAPITL</th>\n",
       "      <th>CENTRL</th>\n",
       "      <th>DUNWOD</th>\n",
       "      <th>GENESE</th>\n",
       "      <th>H Q</th>\n",
       "      <th>HUD VL</th>\n",
       "      <th>LONGIL</th>\n",
       "      <th>MHK VL</th>\n",
       "      <th>MILLWD</th>\n",
       "      <th>N.Y.C.</th>\n",
       "      <th>NORTH</th>\n",
       "      <th>NPX</th>\n",
       "      <th>O H</th>\n",
       "      <th>PJM</th>\n",
       "      <th>WEST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2000 00:00</td>\n",
       "      <td>42.88</td>\n",
       "      <td>39.49</td>\n",
       "      <td>43.70</td>\n",
       "      <td>38.98</td>\n",
       "      <td>39.98</td>\n",
       "      <td>42.92</td>\n",
       "      <td>43.72</td>\n",
       "      <td>41.15</td>\n",
       "      <td>43.08</td>\n",
       "      <td>44.52</td>\n",
       "      <td>40.03</td>\n",
       "      <td>42.04</td>\n",
       "      <td>37.68</td>\n",
       "      <td>38.52</td>\n",
       "      <td>37.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/01/2000 01:00</td>\n",
       "      <td>41.55</td>\n",
       "      <td>38.26</td>\n",
       "      <td>42.34</td>\n",
       "      <td>37.77</td>\n",
       "      <td>38.74</td>\n",
       "      <td>41.58</td>\n",
       "      <td>42.35</td>\n",
       "      <td>39.86</td>\n",
       "      <td>41.74</td>\n",
       "      <td>43.40</td>\n",
       "      <td>38.79</td>\n",
       "      <td>40.73</td>\n",
       "      <td>36.51</td>\n",
       "      <td>37.32</td>\n",
       "      <td>36.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/01/2000 02:00</td>\n",
       "      <td>40.98</td>\n",
       "      <td>37.74</td>\n",
       "      <td>41.76</td>\n",
       "      <td>37.25</td>\n",
       "      <td>38.20</td>\n",
       "      <td>41.01</td>\n",
       "      <td>40.88</td>\n",
       "      <td>39.32</td>\n",
       "      <td>41.17</td>\n",
       "      <td>43.18</td>\n",
       "      <td>38.25</td>\n",
       "      <td>40.17</td>\n",
       "      <td>36.01</td>\n",
       "      <td>36.81</td>\n",
       "      <td>35.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/01/2000 03:00</td>\n",
       "      <td>36.59</td>\n",
       "      <td>33.69</td>\n",
       "      <td>37.28</td>\n",
       "      <td>33.26</td>\n",
       "      <td>34.11</td>\n",
       "      <td>36.62</td>\n",
       "      <td>37.90</td>\n",
       "      <td>35.10</td>\n",
       "      <td>36.75</td>\n",
       "      <td>40.83</td>\n",
       "      <td>34.15</td>\n",
       "      <td>35.86</td>\n",
       "      <td>32.15</td>\n",
       "      <td>32.86</td>\n",
       "      <td>31.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/01/2000 04:00</td>\n",
       "      <td>42.88</td>\n",
       "      <td>39.49</td>\n",
       "      <td>43.70</td>\n",
       "      <td>38.98</td>\n",
       "      <td>39.98</td>\n",
       "      <td>42.92</td>\n",
       "      <td>41.00</td>\n",
       "      <td>41.15</td>\n",
       "      <td>43.08</td>\n",
       "      <td>44.52</td>\n",
       "      <td>40.03</td>\n",
       "      <td>42.04</td>\n",
       "      <td>37.68</td>\n",
       "      <td>38.52</td>\n",
       "      <td>37.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Timestamp  CAPITL  CENTRL  DUNWOD  GENESE    H Q  HUD VL  LONGIL  \\\n",
       "0  01/01/2000 00:00   42.88   39.49   43.70   38.98  39.98   42.92   43.72   \n",
       "1  01/01/2000 01:00   41.55   38.26   42.34   37.77  38.74   41.58   42.35   \n",
       "2  01/01/2000 02:00   40.98   37.74   41.76   37.25  38.20   41.01   40.88   \n",
       "3  01/01/2000 03:00   36.59   33.69   37.28   33.26  34.11   36.62   37.90   \n",
       "4  01/01/2000 04:00   42.88   39.49   43.70   38.98  39.98   42.92   41.00   \n",
       "\n",
       "   MHK VL  MILLWD  N.Y.C.  NORTH    NPX    O H    PJM   WEST  \n",
       "0   41.15   43.08   44.52  40.03  42.04  37.68  38.52  37.49  \n",
       "1   39.86   41.74   43.40  38.79  40.73  36.51  37.32  36.32  \n",
       "2   39.32   41.17   43.18  38.25  40.17  36.01  36.81  35.82  \n",
       "3   35.10   36.75   40.83  34.15  35.86  32.15  32.86  31.98  \n",
       "4   41.15   43.08   44.52  40.03  42.04  37.68  38.52  37.49  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wpGcGtKjorRo",
    "outputId": "888ff2b0-6421-4a58-a0ab-dfd7a294aaa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 222862 entries, 0 to 222861\n",
      "Data columns (total 16 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   Timestamp  222862 non-null  object \n",
      " 1   CAPITL     222862 non-null  float64\n",
      " 2   CENTRL     222862 non-null  float64\n",
      " 3   DUNWOD     222862 non-null  float64\n",
      " 4   GENESE     222862 non-null  float64\n",
      " 5   H Q        222862 non-null  float64\n",
      " 6   HUD VL     222862 non-null  float64\n",
      " 7   LONGIL     222862 non-null  float64\n",
      " 8   MHK VL     222862 non-null  float64\n",
      " 9   MILLWD     222862 non-null  float64\n",
      " 10  N.Y.C.     222862 non-null  float64\n",
      " 11  NORTH      222862 non-null  float64\n",
      " 12  NPX        222862 non-null  float64\n",
      " 13  O H        222862 non-null  float64\n",
      " 14  PJM        222862 non-null  float64\n",
      " 15  WEST       222862 non-null  float64\n",
      "dtypes: float64(15), object(1)\n",
      "memory usage: 27.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (201601, 15)\n",
      "Test shape: (21261, 15)\n",
      "Train years: Index([2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011,\n",
      "       2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022],\n",
      "      dtype='int32', name='Timestamp')\n",
      "Test years: Index([2023, 2024, 2025], dtype='int32', name='Timestamp')\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "df.set_index('Timestamp', inplace=True)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(df['CAPITL'].values.reshape(-1,1))\n",
    "\n",
    "\n",
    "# Creating a data structure with 60 timesteps and 1 output\n",
    "X, y = [], []\n",
    "for i in range(60, len(scaled_data)):\n",
    "    X.append(scaled_data[i-60:i, 0])\n",
    "    y.append(scaled_data[i, 0])\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "# Splitting the data into training and testing sets based on the year\n",
    "train_df = df[df.index < \"2023-01-01\"]\n",
    "test_df = df[df.index >= \"2023-01-01\"]\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "print(\"Train years:\", train_df.index.year.unique())\n",
    "print(\"Test years:\", test_df.index.year.unique())\n",
    "\n",
    "\n",
    "\n",
    "train_scaled = scaler.transform(train_df['CAPITL'].values.reshape(-1,1))\n",
    "test_scaled = scaler.transform(test_df['CAPITL'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "UJ5I44NnpoGr",
    "outputId": "2a60d2a7-0efa-48be-c3ae-1c968e51e240"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\smrez\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m 488/6299\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:55\u001b[0m 133ms/step - loss: 1.6196e-04"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test = [], [], [], []\n",
    "for i in range(60, len(train_scaled)):\n",
    "    X_train.append(train_scaled[i-60:i, 0])\n",
    "    y_train.append(train_scaled[i, 0])\n",
    "for i in range(60, len(test_scaled)):\n",
    "    X_test.append(test_scaled[i-60:i, 0])\n",
    "    y_test.append(test_scaled[i, 0])\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "\n",
    "# Reshaping for GRU\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# GRU Network\n",
    "model_gru = Sequential([\n",
    "    GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)),\n",
    "    Dropout(0.2),\n",
    "    GRU(units=50),\n",
    "    Dropout(0.2),\n",
    "    Dense(units=1)\n",
    "])\n",
    "model_gru.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Fit the model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history_gru = model_gru.fit(X_train, y_train, epochs=2, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# Predictions\n",
    "predicted_prices_gru = model_gru.predict(X_test)\n",
    "predicted_prices_gru = scaler.inverse_transform(predicted_prices_gru)\n",
    "\n",
    "# Evaluation\n",
    "test_actual_gru = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "mse_gru = mean_squared_error(test_actual_gru, predicted_prices_gru)\n",
    "rmse_gru = np.sqrt(mse_gru)\n",
    "mae_gru = mean_absolute_error(test_actual_gru, predicted_prices_gru)\n",
    "print(f\"GRU MAE: {mae_gru}, RMSE: {rmse_gru}\")\n",
    "\n",
    "# Truncate the test_actual array to match the length of predicted_prices\n",
    "test_actual_truncated_gru = test_actual_gru[-len(predicted_prices_gru):]\n",
    "\n",
    "# Adjust the test_df index to match the length of the predictions\n",
    "test_df_index_truncated_gru = test_df.index[-len(predicted_prices_gru):]\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(test_df_index_truncated_gru, test_actual_truncated_gru, label='Actual Price')\n",
    "plt.plot(test_df_index_truncated_gru, predicted_prices_gru, label='Predicted Price')\n",
    "plt.title('Price Prediction for 2023 using GRU')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "\n",
    "# Improve date formatting on x-axis\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M'))\n",
    "plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=30))  # Adjust interval as needed\n",
    "plt.gcf().autofmt_xdate()  # Improve date label formatting\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "yAWlbO35vXz5",
    "outputId": "103d4872-8e2c-4cd5-b05d-980d1abca12b"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history_gru.history['loss'], label='Training Loss')\n",
    "plt.plot(history_gru.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training vs. Validation Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yN4AF69svX5R",
    "outputId": "51f30c04-b038-4903-c425-0a4e99971431"
   },
   "outputs": [],
   "source": [
    "# Predictions\n",
    "predicted_prices = model_gru.predict(X_test)\n",
    "predicted_prices = scaler.inverse_transform(predicted_prices)\n",
    "test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = test_actual_gru - predicted_prices_gru\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(test_actual, predicted_prices))\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "# Plotting residuals\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(residuals, bins=25, alpha=0.75, edgecolor='black')\n",
    "plt.xlabel('Residual')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Residuals')\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot of residuals\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x=test_actual, y=residuals, alpha=0.75)\n",
    "plt.xlabel('Actual Prices')\n",
    "plt.ylabel('Residuals')\n",
    "plt.axhline(y=0, color='r', linestyle='-')\n",
    "plt.title('Residuals vs. Actual Prices')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XlBmzRLOvX-g"
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame for the predicted values\n",
    "predicted_df = pd.DataFrame(predicted_prices_gru, index=test_df_index_truncated_gru, columns=['Predicted'])\n",
    "\n",
    "# Since test_actual_truncated is a NumPy array, convert it back to a DataFrame\n",
    "actual_df = pd.DataFrame(test_actual_truncated_gru, index=test_df_index_truncated_gru, columns=['Actual'])\n",
    "\n",
    "# # Combine actual and predicted values into a single DataFrame for comparison\n",
    "comparison_df = pd.concat([actual_df, predicted_df], axis=1)\n",
    "\n",
    "# # Save the DataFrame to an Excel file\n",
    "comparison_df.to_excel('model_predictions_by_GRU.xlsx')\n",
    "\n",
    "# print(\"Excel file created: model_predictions.xlsx\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
