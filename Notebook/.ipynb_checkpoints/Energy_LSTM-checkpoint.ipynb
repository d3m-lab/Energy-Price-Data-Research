{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "qaCaogK9oxmR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gz6XeJ8co1mr"
   },
   "outputs": [],
   "source": [
    "# prompt: read all the csv files \"D:\\OneDrive - The Pennsylvania State University\\Research DATA\\Dr. Habib & Dr. Reza Data\\Energy Price Market Data\\Day Ahead Price Data_Processed\\USA\\NYISO\" and merge into a one dataframe df\n",
    "\n",
    "folder_path = r\"D:\\OneDrive - The Pennsylvania State University\\Research DATA\\Dr. Habib & Dr. Reza Data\\Energy Price Market Data\\Day Ahead Price Data_Processed\\USA\\NYISO\"\n",
    "\n",
    "all_nyiso_data = pd.DataFrame()\n",
    "\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                df_temp = pd.read_csv(file_path)\n",
    "                all_nyiso_data = pd.concat([all_nyiso_data, df_temp], ignore_index=True)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {file_path}: {e}\")\n",
    "\n",
    "df = all_nyiso_data.copy() # Assign the concatenated dataframe to df\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "HZ2QzqRMo4s0",
    "outputId": "f39eacb3-b475-4a58-8cf9-a862b7ef2e4e"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uKL2TlaXo7Ng",
    "outputId": "73be2ed2-44fa-4890-b186-fc5d8fd888b7"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "df.set_index('Timestamp', inplace=True)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(df['CAPITL'].values.reshape(-1,1))\n",
    "\n",
    "\n",
    "# Creating a data structure with 60 timesteps and 1 output\n",
    "X, y = [], []\n",
    "for i in range(60, len(scaled_data)):\n",
    "    X.append(scaled_data[i-60:i, 0])\n",
    "    y.append(scaled_data[i, 0])\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "# Splitting the data into training and testing sets based on the year\n",
    "train_df = df[df.index < \"2023-01-01\"]\n",
    "test_df = df[df.index >= \"2023-01-01\"]\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "print(\"Train years:\", train_df.index.year.unique())\n",
    "print(\"Test years:\", test_df.index.year.unique())\n",
    "\n",
    "\n",
    "\n",
    "train_scaled = scaler.transform(train_df['CAPITL'].values.reshape(-1,1))\n",
    "test_scaled = scaler.transform(test_df['CAPITL'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qjaKRl9opQIP",
    "outputId": "3af5bdff-67c6-4b83-ab01-c06a839a93ef"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test = [], [], [], []\n",
    "for i in range(60, len(train_scaled)):\n",
    "    X_train.append(train_scaled[i-60:i, 0])\n",
    "    y_train.append(train_scaled[i, 0])\n",
    "for i in range(60, len(test_scaled)):\n",
    "    X_test.append(test_scaled[i-60:i, 0])\n",
    "    y_test.append(test_scaled[i, 0])\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "\n",
    "# Reshaping for LSTM\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# LSTM Network\n",
    "model = Sequential([\n",
    "    LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)),\n",
    "    Dropout(0.2),\n",
    "    LSTM(units=50),\n",
    "    Dropout(0.2),\n",
    "    Dense(units=1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Fit the model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "# Predictions\n",
    "predicted_prices = model.predict(X_test)\n",
    "predicted_prices = scaler.inverse_transform(predicted_prices)\n",
    "\n",
    "# Evaluation\n",
    "test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "mse = mean_squared_error(test_actual, predicted_prices)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(test_actual, predicted_prices)\n",
    "print(f\"LSTM MAE: {mae}, RMSE: {rmse}\")\n",
    "\n",
    "\n",
    "\n",
    "# Truncate the test_actual array to match the length of predicted_prices\n",
    "test_actual_truncated = test_actual[-len(predicted_prices):]\n",
    "\n",
    "# Adjust the test_df index to match the length of the predictions\n",
    "test_df_index_truncated = test_df.index[-len(predicted_prices):]\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(test_df_index_truncated, test_actual_truncated, label='Actual Price')\n",
    "plt.plot(test_df_index_truncated, predicted_prices, label='Predicted Price')\n",
    "plt.title('Price Prediction for 2023')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "\n",
    "# Improve date formatting on x-axis\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M'))\n",
    "plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=30))  # Adjust interval as needed\n",
    "plt.gcf().autofmt_xdate()  # Improve date label formatting\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cx3lUWZ2EAfA"
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame for the predicted values\n",
    "predicted_df = pd.DataFrame(predicted_prices, index=test_df_index_truncated, columns=['Predicted'])\n",
    "\n",
    "# Since test_actual_truncated is a NumPy array, convert it back to a DataFrame\n",
    "actual_df = pd.DataFrame(test_actual_truncated, index=test_df_index_truncated, columns=['Actual'])\n",
    "\n",
    "# # Combine actual and predicted values into a single DataFrame for comparison\n",
    "comparison_df = pd.concat([actual_df, predicted_df], axis=1)\n",
    "\n",
    "# # Save the DataFrame to an Excel file\n",
    "comparison_df.to_excel('model_predictions.xlsx')\n",
    "\n",
    "# print(\"Excel file created: model_predictions.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "s5rnLHQ01mOp",
    "outputId": "1832e2a9-4b42-4b6d-a558-d1580d242d55"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training vs. Validation Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "a4R8BBMZMi-I",
    "outputId": "00048b2e-d00f-404e-8e6f-a95d2cbdb7e9"
   },
   "outputs": [],
   "source": [
    "# Predictions\n",
    "predicted_prices = model.predict(X_test)\n",
    "predicted_prices = scaler.inverse_transform(predicted_prices)\n",
    "test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = test_actual - predicted_prices\n",
    "\n",
    "# Plotting residuals\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(residuals, bins=25, alpha=0.75, edgecolor='black')\n",
    "plt.xlabel('Residual')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Residuals')\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot of residuals\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x=test_actual, y=residuals, alpha=0.75)\n",
    "plt.xlabel('Actual Prices')\n",
    "plt.ylabel('Residuals')\n",
    "plt.axhline(y=0, color='r', linestyle='-')\n",
    "plt.title('Residuals vs. Actual Prices')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
