{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OB2q0svlm05j",
    "outputId": "8b1ebe5b-2518-466f-dd2e-1d3b10edc5c3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mmb3OZLCLxJh"
   },
   "source": [
    "<h1> Reading the Dataset </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ctNkjCJfnF12"
   },
   "outputs": [],
   "source": [
    "# prompt: read all the csv files \"D:\\OneDrive - The Pennsylvania State University\\Research DATA\\Dr. Habib & Dr. Reza Data\\Energy Price Market Data\\Day Ahead Price Data_Processed\\USA\\NYISO\" and merge into a one dataframe df\n",
    "\n",
    "folder_path = r\"D:\\OneDrive - The Pennsylvania State University\\Research DATA\\Dr. Habib & Dr. Reza Data\\Energy Price Market Data\\Day Ahead Price Data_Processed\\USA\\NYISO\"\n",
    "\n",
    "all_nyiso_data = pd.DataFrame()\n",
    "\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                df_temp = pd.read_csv(file_path)\n",
    "                all_nyiso_data = pd.concat([all_nyiso_data, df_temp], ignore_index=True)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {file_path}: {e}\")\n",
    "\n",
    "df = all_nyiso_data.copy() # Assign the concatenated dataframe to df\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "hLApLaGSnMOM",
    "outputId": "f3d9f753-3d37-4f70-d2e2-b78037f8b12a"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LKuaE5ipnOaf",
    "outputId": "9b12bcfb-3cbf-4f9a-b761-1d4852ff7a56"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ta5JSeSx6jto",
    "outputId": "5eb8d308-53c5-4fbf-c6bd-1ca92029c669"
   },
   "outputs": [],
   "source": [
    "# Create a date range from January 1, 2016, to December 31, 2023, with hourly frequency\n",
    "date_range = pd.date_range(start='2016-01-01', end='2023-12-31 23:00:00', freq='H')\n",
    "\n",
    "len(date_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FDtLfTPyn9CC",
    "outputId": "1a7aa505-00ea-41e2-db51-aad160a3b1e6"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBxCCsw7L6iW"
   },
   "source": [
    "<h1>Plotting the DATA</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "8bmJIIE8n9E2",
    "outputId": "ce30e1fd-e5b1-4d26-93d9-6fdfcaba5826"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting time series\n",
    "df.set_index('Timestamp')['CAPITL'].plot(figsize=(15, 6))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g3Kbu-B6phJp"
   },
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ZuBX4UZJqC2U",
    "outputId": "fcd0ff26-39a9-4c5a-8893-7b9626f5304b"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "YeiBJZkXqE1P",
    "outputId": "175fd879-2995-4b1e-d959-5426324f5e05"
   },
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QI7sASqvMBG9"
   },
   "source": [
    "<h1> Energy Price Data by YEAR </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "ddkS1JyJoddr",
    "outputId": "315a156d-6eee-4dd0-f782-41923fbcbf04"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure your DataFrame is named df and has columns 'Date' and 'Price'\n",
    "# Convert 'Date' to datetime if it's not already\n",
    "\n",
    "df1['Timestamp'] = pd.to_datetime(df1['Timestamp'])\n",
    "\n",
    "# Extract year and month from the Date\n",
    "df1['Year'] = df1['Timestamp'].dt.year\n",
    "df1['Month'] = df1['Timestamp'].dt.month\n",
    "\n",
    "# Pivot the data for easier plotting\n",
    "df1_pivot = df1.pivot_table(values='CAPITL', index='Month', columns='Year')\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.lineplot(data=df1_pivot)\n",
    "plt.title('Seasonal Plot by Year')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Price')\n",
    "plt.xticks(range(1, 13))  # To show each month on the x-axis\n",
    "plt.legend(title='Year', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "XtOkTnqjooHA",
    "outputId": "a74044bd-97c2-4e7b-b3df-88549964fc12"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "P-alZrBEn9Hq",
    "outputId": "eb7248de-56be-4be0-f8ef-28fb2e4a2feb"
   },
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJwaK0GpMIaX"
   },
   "source": [
    "<h1> Price By Individual Year </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508
    },
    "id": "YvL_HkH-n9KS",
    "outputId": "b7a8b71c-6fec-49fe-c504-09a4821e8e88"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is named df with columns 'Date' and 'Price'\n",
    "# Convert 'Date' to datetime if it's not already\n",
    "df1['Timestamp'] = pd.to_datetime(df1['Timestamp'])\n",
    "\n",
    "# Extracting year and month\n",
    "df1['Year'] = df1['Timestamp'].dt.year\n",
    "df1['Month'] = df1['Timestamp'].dt.strftime('%b')  # %b gives the month abbreviation\n",
    "\n",
    "# Creating a FacetGrid to plot each year's data in a separate subplot\n",
    "g = sns.FacetGrid(df1, col='Year', col_wrap=4, height=3, aspect=1.5)\n",
    "g = g.map(sns.lineplot, 'Month', 'Price')\n",
    "\n",
    "# Adjusting the x-axis labels for better readability\n",
    "for ax in g.axes:\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "\n",
    "plt.subplots_adjust(top=0.9)\n",
    "g.fig.suptitle('Seasonal Subseries Plot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULKY9SMYMPgp"
   },
   "source": [
    "<h1> Energy price by Individual Month </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "id": "vVRFbKzyn9M8",
    "outputId": "d478666b-04ec-4fec-8b81-140de5e1ceb9"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is named df with columns 'Date' and 'Price'\n",
    "# Convert 'Date' to datetime if it's not already\n",
    "df1['Timestamp'] = pd.to_datetime(df1['Timestamp'])\n",
    "\n",
    "# Extracting year and month\n",
    "df1['Year'] = df1['Timestamp'].dt.year\n",
    "df1['Month'] = df1['Timestamp'].dt.month\n",
    "\n",
    "# Convert month numbers to names for better readability\n",
    "import calendar\n",
    "df1['Month'] = df1['Month'].apply(lambda x: calendar.month_abbr[x])\n",
    "\n",
    "# Creating a FacetGrid to plot each month's data in a separate subplot\n",
    "g = sns.FacetGrid(df1, col='Month', col_wrap=4, height=3, aspect=1.5)\n",
    "g = g.map_dataframe(sns.lineplot, x='Year', y='CAPITL')\n",
    "\n",
    "plt.subplots_adjust(top=0.9)\n",
    "g.fig.suptitle('Seasonal Subseries Plot by Month')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvSGz8hpMWUt"
   },
   "source": [
    "<h1> Time Series Decomposition </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7t2AkwxMn9Pk",
    "outputId": "665ad44c-7a73-4e4b-f26d-dc0ee6084e1c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Ensure that 'Date' is the index and in the correct DateTime format\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "df.set_index('Timestamp', inplace=True)\n",
    "\n",
    "# Decompose the time series with daily frequency for hourly data\n",
    "decomposition = seasonal_decompose(df['CAPITL'], model='additive', period=24)  # adjust period if different seasonality is suspected\n",
    "\n",
    "# Plot the decomposed components\n",
    "plt.rcParams.update({'figure.figsize': (10,10)})\n",
    "decomposition.plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hANX0p74n9SM",
    "outputId": "9f34fd3d-1487-4544-af9f-414a06757a13"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Ensure that 'Date' is the index and in the correct DateTime format\n",
    "#df['Date'] = pd.to_datetime(df['Date'])\n",
    "#df.set_index('Date', inplace=True)\n",
    "\n",
    "# Decompose the time series with daily frequency for hourly data\n",
    "decomposition = seasonal_decompose(df['CAPITL'], model='additive', period=24*7)  # adjust period if different seasonality is suspected\n",
    "\n",
    "# Plot the decomposed components\n",
    "plt.rcParams.update({'figure.figsize': (10,10)})\n",
    "decomposition.plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HW_zicCUMfgW"
   },
   "source": [
    "<h1> Model 1: XGBOOST </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "5n8Jq5fNn9U4",
    "outputId": "f1ceade6-812e-4a7d-aa65-d854413fae34"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df is your DataFrame with 'Date' as the index and 'Price' as the target.\n",
    "\n",
    "\n",
    "# Feature Engineering\n",
    "for lag in range(1, 25):  # 24-hour lags to capture one full day's cycle\n",
    "    df[f'lag_{lag}'] = df['CAPITL'].shift(lag)\n",
    "\n",
    "# Remove the first 24 rows because of NaNs introduced by lagging\n",
    "df = df.dropna()\n",
    "\n",
    "# Splitting the data\n",
    "train = df[:'2022']\n",
    "test = df['2023']\n",
    "\n",
    "# Separate features and target\n",
    "X_train = train.drop('CAPITL', axis=1)\n",
    "y_train = train['CAPITL']\n",
    "X_test = test.drop('CAPITL', axis=1)\n",
    "y_test = test['CAPITL']\n",
    "\n",
    "# Model Training\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1, max_depth=5)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"MAE: {mae}, RMSE: {rmse}\")\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(y_test.index, y_test, label='Actual')\n",
    "plt.plot(y_test.index, y_pred, label='Predicted')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "id": "s_59cpT3n9XT",
    "outputId": "a8e9f2f9-c3d1-4fca-861f-7c5f3d53cb4d"
   },
   "outputs": [],
   "source": [
    "# Assuming y_test and y_pred are pandas Series with a DateTime index\n",
    "comparison_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "\n",
    "# If you want to see the comparison for one specific day\n",
    "# Let's say we want to see this for January 1st, 2023\n",
    "date_to_compare = '2023-01-01'\n",
    "one_day_comparison = comparison_df.loc[date_to_compare]\n",
    "\n",
    "# Now let's display this as a table\n",
    "one_day_comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aRrGLS0QMm-E"
   },
   "source": [
    "<h1> Model 2: Random Forest </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "id": "PaZT_EWDrt9u",
    "outputId": "36e7a0f0-9bc0-4662-f60e-c6dd151e3a37"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Assuming the same feature engineering, and train/test split as with XGBoost\n",
    "\n",
    "# Model Training\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction\n",
    "rf_y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "rf_mse = mean_squared_error(y_test, rf_y_pred)\n",
    "rf_rmse = np.sqrt(rf_mse)\n",
    "rf_mae = mean_absolute_error(y_test, rf_y_pred)\n",
    "print(f\"Random Forest MAE: {rf_mae}, RMSE: {rf_rmse}\")\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(y_test.index, y_test, label='Actual')\n",
    "plt.plot(y_test.index, rf_y_pred, label='Predicted by Random Forest')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "id": "-9tEF5h9saQf",
    "outputId": "158db731-53b8-4d9c-fa5e-d3a14a5ba37e"
   },
   "outputs": [],
   "source": [
    "# Assuming y_test and rf_y_pred are pandas Series with a DateTime index\n",
    "rf_comparison_df = pd.DataFrame({'Actual': y_test, 'Predicted': rf_y_pred})\n",
    "\n",
    "# If you want to see the comparison for one specific day\n",
    "# Let's say we want to see this for January 1st, 2023\n",
    "date_to_compare = '2023-01-01'\n",
    "one_day_rf_comparison = rf_comparison_df.loc[date_to_compare]\n",
    "\n",
    "# Now let's display this as a table\n",
    "one_day_rf_comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_QusEOYM5M7"
   },
   "source": [
    "<h1> Model 3: FBPROPHET </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639
    },
    "id": "VtJxE3LitDwE",
    "outputId": "438a1a87-58bd-472e-dab8-9d49a7a0a158"
   },
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "\n",
    "\n",
    "# Assuming df is your DataFrame with 'Date' as the index and 'Price' as the target.\n",
    "\n",
    "# Prophet requires the data to be in a DataFrame with two columns: 'ds' and 'y'\n",
    "prophet_df = df.reset_index().rename(columns={'Timestamp': 'ds', 'CAPITL': 'y'})\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_prophet_df = prophet_df[prophet_df['ds'] < '2023-01-01']\n",
    "test_prophet_df = prophet_df[prophet_df['ds'] >= '2023-01-01']\n",
    "\n",
    "# Initialize the Prophet model\n",
    "prophet_model = Prophet()\n",
    "\n",
    "# Fit the model on the training data\n",
    "prophet_model.fit(train_prophet_df)\n",
    "\n",
    "# Create a DataFrame for predictions\n",
    "future = prophet_model.make_future_dataframe(periods=len(test_prophet_df), freq='H')\n",
    "\n",
    "# Predict\n",
    "forecast = prophet_model.predict(future)\n",
    "\n",
    "# Extract the predicted values for the test set\n",
    "predicted_prophet = forecast['yhat'][-len(test_prophet_df):]\n",
    "\n",
    "# Evaluation - calculating metrics\n",
    "prophet_mse = mean_squared_error(test_prophet_df['y'], predicted_prophet)\n",
    "prophet_rmse = np.sqrt(prophet_mse)\n",
    "prophet_mae = mean_absolute_error(test_prophet_df['y'], predicted_prophet)\n",
    "print(f\"Prophet MAE: {prophet_mae}, RMSE: {prophet_rmse}\")\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(test_prophet_df['ds'], test_prophet_df['y'], label='Actual')\n",
    "plt.plot(test_prophet_df['ds'], predicted_prophet.values, label='Predicted by Prophet')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xwu7GjH2NBXR"
   },
   "source": [
    "<h1> Model 4: LSTM </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "kGlaDc-Cyua4",
    "outputId": "06aa24aa-d1c1-48c0-b6cc-1a4dcc0f4a2b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df is your DataFrame with 'Date' as the index and 'Price' as the target.\n",
    "\n",
    "# Data Preprocessing\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(df['CAPITL'].values.reshape(-1,1))\n",
    "\n",
    "# Creating a data structure with 60 timesteps and 1 output\n",
    "X = []\n",
    "y = []\n",
    "for i in range(60, len(scaled_data)):\n",
    "    X.append(scaled_data[i-60:i, 0])\n",
    "    y.append(scaled_data[i, 0])\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "train_size = int(len(df) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Reshaping for LSTM\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# LSTM Network\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model.fit(X_train, y_train, epochs=2, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# Predictions\n",
    "predicted_prices = model.predict(X_test)\n",
    "predicted_prices = scaler.inverse_transform(predicted_prices)\n",
    "\n",
    "# Evaluation\n",
    "test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "mse = mean_squared_error(test_actual, predicted_prices)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(test_actual, predicted_prices)\n",
    "print(f\"LSTM MAE: {mae}, RMSE: {rmse}\")\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(test_actual, label='Actual Price')\n",
    "plt.plot(predicted_prices, label='Predicted Price')\n",
    "plt.title('Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3AY4YwQ73p8S",
    "outputId": "662b4573-bf06-4202-ad1f-55506f26b64a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your original DataFrame indexed by dates\n",
    "# Get the corresponding dates for the test set\n",
    "test_dates = df.index[-len(predicted_prices):]\n",
    "\n",
    "# Create a DataFrame for the predicted values with correct dates\n",
    "predicted_df = pd.DataFrame(predicted_prices, index=test_dates, columns=['Predicted'])\n",
    "\n",
    "# Assuming 'test_actual' contains the actual test set values\n",
    "# Create a DataFrame for the actual values with the same dates\n",
    "actual_df = pd.DataFrame(test_actual, index=test_dates, columns=['Actual'])\n",
    "\n",
    "# Combine actual and predicted values into a single DataFrame for comparison\n",
    "comparison_df = pd.concat([actual_df, predicted_df], axis=1)\n",
    "\n",
    "# Select a specific day for comparison\n",
    "specific_day = '2023-01-01'  # replace with the date you are interested in\n",
    "one_day_comparison = comparison_df.loc[specific_day]\n",
    "\n",
    "# Display the comparison table for that day\n",
    "print(one_day_comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "lDyScXkUnfHu",
    "outputId": "3dc756c9-f068-4b7a-b850-33b72baedf23"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your original DataFrame indexed by dates\n",
    "# Get the corresponding dates for the test set of the year 2023\n",
    "test_dates = df['2023'].index  # This selects only the dates for the year 2023\n",
    "\n",
    "# Create a DataFrame for the predicted values with correct dates\n",
    "predicted_df = pd.DataFrame(predicted_prices, index=test_dates, columns=['Predicted'])\n",
    "\n",
    "# Assuming 'test_actual' contains the actual test set values\n",
    "# Create a DataFrame for the actual values with the same dates\n",
    "actual_df = pd.DataFrame(test_actual, index=test_dates, columns=['Actual'])\n",
    "\n",
    "# Combine actual and predicted values into a single DataFrame for comparison\n",
    "comparison_df = pd.concat([actual_df, predicted_df], axis=1)\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "comparison_df.to_excel('predicted_vs_actual_2023.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2kqpF3qjNVU1"
   },
   "source": [
    "<h1> Model 5: TCN </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "WkoTBcgX4Sae",
    "outputId": "31b127ff-73f9-408f-875b-a470e2a3631b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Conv1D, GlobalAveragePooling1D\n",
    "\n",
    "# Assuming df is your DataFrame with 'Date' as the index and 'Price' as the target.\n",
    "\n",
    "# Data Preprocessing\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(df['CAPITL'].values.reshape(-1,1))\n",
    "\n",
    "# Create dataset with 60 timesteps (you can adjust this)\n",
    "X = []\n",
    "y = []\n",
    "for i in range(60, len(scaled_data)):\n",
    "    X.append(scaled_data[i-60:i, 0])\n",
    "    y.append(scaled_data[i, 0])\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "# Split the data\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Reshape for TCN\n",
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_test = np.expand_dims(X_test, axis=2)\n",
    "\n",
    "# TCN Model\n",
    "model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=6, padding='causal', activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    Conv1D(filters=64, kernel_size=6, padding='causal', activation='relu'),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(lr=1e-3), loss='mean_squared_error')\n",
    "\n",
    "# Model Training\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model.fit(X_train, y_train, epochs=2, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# Predictions\n",
    "predicted_prices = model.predict(X_test)\n",
    "predicted_prices = scaler.inverse_transform(predicted_prices)\n",
    "\n",
    "# Evaluation\n",
    "test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "mse = mean_squared_error(test_actual, predicted_prices)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(test_actual, predicted_prices)\n",
    "print(f\"TCN MAE: {mae}, RMSE: {rmse}\")\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(test_actual, label='Actual Price')\n",
    "plt.plot(predicted_prices, label='Predicted Price')\n",
    "plt.title('Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "id": "5gbHHYoFseWF",
    "outputId": "691f84c2-963a-48ea-f366-320858428928"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your original DataFrame with 'Date' as the index\n",
    "# Ensure the test set extraction matches the creation of y_test\n",
    "\n",
    "# If y_test corresponds to a specific subset of the year 2023, adjust this line accordingly\n",
    "test_dates = df.loc[your_specific_criteria].index  # Replace 'your_specific_criteria' appropriately\n",
    "\n",
    "# Ensure y_test and predicted_prices are of the same length\n",
    "if len(predicted_prices) != len(test_dates):\n",
    "    raise ValueError(\"Length of predicted prices does not match the length of test dates\")\n",
    "\n",
    "# Create a DataFrame for the predicted values with correct dates\n",
    "predicted_df = pd.DataFrame(predicted_prices, index=test_dates, columns=['Predicted'])\n",
    "\n",
    "# Since y_test is likely a NumPy array, convert it back to a DataFrame with the test index\n",
    "actual_df = pd.DataFrame(test_actual, index=test_dates, columns=['Actual'])\n",
    "\n",
    "# Combine actual and predicted values into a single DataFrame for comparison\n",
    "comparison_df = pd.concat([actual_df, predicted_df], axis=1)\n",
    "\n",
    "# If you want to display the comparison for the entire test set\n",
    "print(comparison_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
