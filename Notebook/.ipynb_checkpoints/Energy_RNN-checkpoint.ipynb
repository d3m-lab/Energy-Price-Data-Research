{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VAZON2YbNpYX",
    "outputId": "46def7d7-c144-4973-fc17-f59e06638dc2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "reVxKRQwOUMN"
   },
   "outputs": [],
   "source": [
    "# prompt: read all the csv files \"D:\\OneDrive - The Pennsylvania State University\\Research DATA\\Dr. Habib & Dr. Reza Data\\Energy Price Market Data\\Day Ahead Price Data_Processed\\USA\\NYISO\" and merge into a one dataframe df\n",
    "\n",
    "folder_path = r\"D:\\OneDrive - The Pennsylvania State University\\Research DATA\\Dr. Habib & Dr. Reza Data\\Energy Price Market Data\\Day Ahead Price Data_Processed\\USA\\NYISO\"\n",
    "\n",
    "all_nyiso_data = pd.DataFrame()\n",
    "\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                df_temp = pd.read_csv(file_path)\n",
    "                all_nyiso_data = pd.concat([all_nyiso_data, df_temp], ignore_index=True)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {file_path}: {e}\")\n",
    "\n",
    "df = all_nyiso_data.copy() # Assign the concatenated dataframe to df\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Odqnv6gOOUOt",
    "outputId": "3ac65d5e-d8b9-4257-8d2b-2fc600848566"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CB5l0fdzOURV",
    "outputId": "5a68ca03-84de-432b-9ecf-cc63516dff59"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "df.set_index('Timestamp', inplace=True)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(df['CAPITL'].values.reshape(-1,1))\n",
    "\n",
    "\n",
    "# Creating a data structure with 60 timesteps and 1 output\n",
    "X, y = [], []\n",
    "for i in range(60, len(scaled_data)):\n",
    "    X.append(scaled_data[i-60:i, 0])\n",
    "    y.append(scaled_data[i, 0])\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "# Splitting the data into training and testing sets based on the year\n",
    "train_df = df[df.index < \"2023-01-01\"]\n",
    "test_df = df[df.index >= \"2023-01-01\"]\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "print(\"Train years:\", train_df.index.year.unique())\n",
    "print(\"Test years:\", test_df.index.year.unique())\n",
    "\n",
    "\n",
    "\n",
    "train_scaled = scaler.transform(train_df['CAPITL'].values.reshape(-1,1))\n",
    "test_scaled = scaler.transform(test_df['CAPITL'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 797
    },
    "id": "2nsqxvQfPxK4",
    "outputId": "2dd1402f-2832-4f9a-c0ce-994f79e9a8fd"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test = [], [], [], []\n",
    "for i in range(60, len(train_scaled)):\n",
    "    X_train.append(train_scaled[i-60:i, 0])\n",
    "    y_train.append(train_scaled[i, 0])\n",
    "for i in range(60, len(test_scaled)):\n",
    "    X_test.append(test_scaled[i-60:i, 0])\n",
    "    y_test.append(test_scaled[i, 0])\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "\n",
    "# Reshaping for RNN\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# RNN Network\n",
    "model_rnn = Sequential([\n",
    "    SimpleRNN(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)),\n",
    "    Dropout(0.2),\n",
    "    SimpleRNN(units=50),\n",
    "    Dropout(0.2),\n",
    "    Dense(units=1)\n",
    "])\n",
    "model_rnn.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Fit the model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history_rnn = model_rnn.fit(X_train, y_train, epochs=2, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# Predictions\n",
    "predicted_prices_rnn = model_rnn.predict(X_test)\n",
    "predicted_prices_rnn = scaler.inverse_transform(predicted_prices_rnn)\n",
    "\n",
    "# Evaluation\n",
    "test_actual_rnn = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "mse_rnn = mean_squared_error(test_actual_rnn, predicted_prices_rnn)\n",
    "rmse_rnn = np.sqrt(mse_rnn)\n",
    "mae_rnn = mean_absolute_error(test_actual_rnn, predicted_prices_rnn)\n",
    "mape_rnn = np.mean(np.abs((test_actual_rnn - predicted_prices_rnn) / test_actual_rnn)) * 100\n",
    "\n",
    "# Calculate R² value\n",
    "r2_rnn = r2_score(test_actual_rnn, predicted_prices_rnn)\n",
    "\n",
    "print(f\"MAPE: {mape_rnn}%, R² Value: {r2_rnn}\")\n",
    "print(f\"RNN MAE: {mae_rnn}, RMSE: {rmse_rnn}\")\n",
    "\n",
    "# Truncate the test_actual_rnn array to match the length of predicted_prices_rnn\n",
    "test_actual_truncated_rnn = test_actual_rnn[-len(predicted_prices_rnn):]\n",
    "\n",
    "# Adjust the test_df index to match the length of the predictions\n",
    "test_df_index_truncated_rnn = test_df.index[-len(predicted_prices_rnn):]\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(test_df_index_truncated_rnn, test_actual_truncated_rnn, label='Actual Price')\n",
    "plt.plot(test_df_index_truncated_rnn, predicted_prices_rnn, label='Predicted Price')\n",
    "plt.title('Price Prediction for 2023 using RNN')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "\n",
    "# Improve date formatting on x-axis\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M'))\n",
    "plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=30))  # Adjust interval as needed\n",
    "plt.gcf().autofmt_xdate()  # Improve date label formatting\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "id": "M0o8mbzsmpV5",
    "outputId": "5e281616-5f44-4a15-8aa9-112fc59e8586"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history_rnn.history['loss'], label='Training Loss')\n",
    "plt.plot(history_rnn.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training vs. Validation Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "FNLHz3Nemz4x",
    "outputId": "0205d50b-884a-4133-b304-2bfda95aaa09"
   },
   "outputs": [],
   "source": [
    "# Predictions\n",
    "predicted_prices = model_rnn.predict(X_test)\n",
    "predicted_prices = scaler.inverse_transform(predicted_prices)\n",
    "test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = test_actual - predicted_prices\n",
    "\n",
    "# Plotting residuals\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(residuals, bins=25, alpha=0.75, edgecolor='black')\n",
    "plt.xlabel('Residual')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Residuals')\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot of residuals\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x=test_actual, y=residuals, alpha=0.75)\n",
    "plt.xlabel('Actual Prices')\n",
    "plt.ylabel('Residuals')\n",
    "plt.axhline(y=0, color='r', linestyle='-')\n",
    "plt.title('Residuals vs. Actual Prices')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
